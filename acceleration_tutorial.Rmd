---
title: 'HMM in Marine Sciences: model selection, covariates, hierarchical structures' 
author: "Marco Gallegos Herrada and Vianey Leos Barajas"
output: 
  bookdown::html_document2:
    number_sections: true
    highlight: tango
    toc: yes
    toc_float: yes
    theme: cosmo
editor_options:
  chunk_output_type: console
---

<!-- To be able to have continuous line numbers -->
```{=html}
<style>
body
  { counter-reset: source-line 0; }
pre.numberSource code
  { counter-reset: none; }
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)
```



```{r}
library(readr)
library(momentuHMM)
library(ggplot2)
library(dplyr)
library(lubridate)
library(data.tree)
library(DiagrammeR)
```

# Tutorial objectives

The goal of this tutorial is to explore how to fit hidden Markov models to accelerometer data, incorporate covariates into the transition probabilities, 

The goal of this tutorial is to explore fitting hidden Markov models to accelerometer data, incorporate covariates into the transition probabilities, and select for the best candidate model. We use 4 days of acceleration data obtained from a free-ranging blacktip reef shark at Palmyra Atoll in the central Pacific Ocean (data taken from Leos-Barajas et al. 2017). 


# Accelerometer data

Accelerometer devices measure up to three axes, which can be described relative to the body of the animal: longitudinal (surge), lateral (sway) and dorsoventral (heave). These devices are becoming more prevalent in the fields of animal biologging data as they provide a means of measuring activity in a meaningful and quantitative way. From tri-axial acceleration data, we can also derive several measures that summarize effort or exertion and relate acceleration  to activity levels such as overall dynamic body acceleration (ODBA) and vectorial dynamic body acceleration (VeDBA). These metrics can be used to reduce the dimensionality of three-dimension acceleration data while retaining important information. Further, because acceleration data is often at high temporal resolutions over time, it also naturally exhibits a large degree of autocorrelation, making it impossible to assume independence between sequential observations. As we have learned, HMMs can account for the autocorrelation present in the data while assuming that the data were generated according to a finite set of (unobserved) behaviors making them a good candidate model for this type of data structure. Today, we will fit an HMM to the ODBA of a blacktip shark, calculated every second. 

For the blacktip shark, we have time of day, water temperature, depth and ODBA. Since one of our goals is to use the time of observations (second of the day) as a covariate, we also need to extract this information from the time variable. For the interest of time, we use the 1-minute averaged depth and ODBA values so that the models can finish running within this tutorial. 

```{r}
# Load data 
BlacktipB <- read_delim("BlacktipB.txt", 
                        delim = "\t", escape_double = FALSE, 
                        trim_ws = TRUE)

# Transform into proper time format and take 1-min avg
BlacktipB_1min = BlacktipB %>% 
  mutate(Time = as.POSIXct(Time,format = "%m/%d/%Y %H:%M")) %>% 
  group_by(Time = cut(Time, breaks = "1 min")) %>%
  summarise(ODBA_avg = mean(ODBA),
            temp_avg = mean(Temp)) %>%
  ungroup() %>%
  mutate(Time = as.POSIXct(Time,format = "%Y-%m-%d %H:%M:%S")) %>%
  as.data.frame()
  
head(BlacktipB_1min)
```


# Fitting our model

**Note:** 0 and 2 refers to the original dataset and I'm not sure what is value is the best to filter extreme observations

Looking at the ODBA values through the observed period, we find ODBA is unusually high at some times -- for this shark we assumed that values between 0 and 2 were consistent with what we expected. Because accommodating extreme values can pose a problem for identification of an adequate state-dependent distribution in our HMM, we removed them from the data set. However, note that in general, deciding whether to remove extreme values or not will more likely depend on whether we find appropriate distributional forms that can accommodate them. Generally, we need to make sure that extreme values are in fact some artefact of the data collection process, not representative of a behavior of interest, or inconsistent with what we are trying to capture as well. Removing data is not good general practice but instead we can assess on a case-by-case basis. 

We can see the original time series here across the four days: 

```{r}
BlacktipB_1min %>% 
  ggplot(aes(Time,ODBA_avg)) + 
  geom_line() 
```



And now, the modified time series with values above 2.0 removed. Note that here we ignore the fact that we do not have data for these time points.

Now, we are ready to start to look for models for this data!


Given our data, we are interested in finding possible behaviours through the observation process (ODBA). Let's take a quick look at the histogram of the observations.

```{r, echo=F}
hist(BlacktipB_1min$ODBA_avg, 
     breaks = 50, 
     main="Histogram of ODBA", 
     xlab = "ODBA")
```


As we have indicated before, the best way to start when fitting a hidden Markov model is to keep things simple. In this case, we will be considering 2 behavioral states, with gamma state-dependent distributions, and no covariates for the transition probability matrix. As mentioned in previous tutorials, now is time to implement the decisions that we have made so far. For the choice of initial parameter values we can take a quick peak at the data (e.g., using the plots above). From the plots above, we specify the means of our state-dependent distributions as 0.001 and 0.003. 


Now that the data is ready for modeling, we choose to fit a 2-state hidden Markov model. For this purpose, we first need to assign the class `momentuHMMData` to the data in order to be presentable for the functions related to `momentuHMM`.

```{r}
BlacktipBData = prepData(BlacktipB_1min,coordNames = NULL)
```

Let's fit our model and take a look at the output of the fitted model. 

```{r, cache=TRUE}
fit1 = fitHMM(BlacktipBData,nbStates=2,dist=list(ODBA_avg="gamma"),Par0 = list(ODBA_avg=c(.001,.003,1,1)))

fit1
```

We can also plot the results to obtain a visual representation of the fitted model.

```{r}
plot(fit1,breaks = 80)
```

Let's look at the pseudo-residuals.

```{r}
plotPR(fit1)
```

We can also compute the most likely sequence of states.

```{r, cache=TRUE}
# identify most likely state using the Viterbi algorithm
BlacktipB_1min$state <- viterbi(fit1)

# proportion of the behaviour states during the observed period
table(BlacktipB_1min$state)/length(BlacktipB_1min$state)

BlacktipB_1min %>% mutate(day = day(Time)) %>% 
  ggplot(aes(Time,state)) + 
  #facet_wrap(~day,scales = "free_x") + 
  geom_point()
```

Let's include retryFits in the fitHMM function. This can take time to run.

```{r, cache=TRUE}
set.seed(147)
fit1_s2 <- fitHMM(BlacktipBData,
                  nbState = 2,
                  dist=list(ODBA_avg="gamma"),
                  Par0 = list(ODBA_avg=c(.001,.003,1,1)),
                  retryFits=10)
fit1_s2
```

Seems nothing changed at all!

Now let's go further and include a high perturbation in one of the initial values (instead of .001 and .003, let's do .001 and 1). Do we still have similar estimated coefficients and log likelihood? (no matter the initial values, the coefficients should be similar)

```{r, cache=TRUE}
fit1_s2_long <- fitHMM(BlacktipBData,
                  nbState = 2,
                  dist=list(ODBA_avg="gamma"),
                  Par0 = list(ODBA_avg=c(.001,1,1,1)))

fit1_s2_long
```

Let's look at the pseudo-residuals.

```{r}
plotPR(fit1_s2_long)
```

You may get warnings.

We can see that there is high autocorrelation and some deviation from normality.

We can also compute the most likely sequence of states. What can we infer from this? Is there something else we can say from this? According to fitted model, can we see if there is any interesting pattern?

```{r, cache=TRUE}
# identify most likely state using the Viterbi algorithm
BlacktipB_1min$state_wildPar0 <- viterbi(fit1_s2_long)

# proportion of the behaviour states during the observed period
table(BlacktipB_1min$state_wildPar0)/length(BlacktipB_1min$state_wildPar0)

BlacktipB_1min %>% mutate(day = day(Time)) %>% ggplot(aes(Time,state_wildPar0)) + facet_wrap(~day) + geom_point()

```

Here we can see that there is only one state when we use these new starting values, this is an indication that there may be problems.

# Incorporating covariates

As in Leos-Barajas et al. 2017, we can incorporate other information that may help explain the values of ODBA. In this case, we consider the minute of the day of every observation. Time of day is represented by two trigonometric functions with period 24 h, $cos(2\pi (t/60)/24)$ and $sin(2\pi (t/60)/24$. Using the function cosinor, we can convert our data stream to something that is useful for us. As well, we need to provide the formula corresponding to the regression that will be stored in the transition probability values.

```{r, cache=TRUE}
# formula corresponding to the regression coefficients for the transition probabilities
# re-prep data
BlacktipB_1min <- BlacktipB_1min %>%
  mutate(lag = 0:(n() - 1),
         sin_part = sin(2*pi*lag*(1/60)/24),
         cos_part = cos(2*pi*lag*(1/60)/24)
         )

BlacktipBData = prepData(BlacktipB_1min,coordNames = NULL, covNames = c("sin_part", "cos_part"))

# re-fit model 1
fit1 = fitHMM(BlacktipBData,nbStates=2,dist=list(ODBA_avg="gamma"),Par0 = list(ODBA_avg=c(.1,.3,1,1)))


formula = ~ sin_part + cos_part
Par0_fit2 <- getPar0(model=fit1, 
                     formula=formula)

fit2 = fitHMM(BlacktipBData,nbStates=2,dist=list(ODBA_avg="gamma"),Par0 = Par0_fit2$Par,formula=formula)

fit2
```


```{r, cache=TRUE}
plot(fit2,breaks=80)
```

Let's explore the results. Do the coefficients vary much? What about the ACF? Did the autocorrelation decrease with this innovation?

```{r}
plotPR(fit2)
```

## Model section: Akaike Information Criteria (AIC)

Akaike information criteria (AIC) is a model selection criteria to select models. In a few words, the higher, the better (or equivalently, since values are always negative, the closer to zero, the better).
We can also take a quick look at the Akaike information criteria (AIC) for the two models to do a comparison. 

```{r}
AIC(fit1)
AIC(fit2)
```


# Exercises
